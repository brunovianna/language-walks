{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunovianna/language-walks/blob/main/meaning_walks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9EBc437WDOs",
        "outputId": "0c8df28d-0526-40de-a347-8c640e8adee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzFDHH2erVY8",
        "outputId": "90f15f04-2825-4074-a98f-d8a3c93ff3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/sd-playground/’: File exists\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-cv\n",
            "  Downloading keras_cv-0.4.2-py3-none-any.whl (634 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.9/634.9 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.9/dist-packages (from keras-cv) (4.8.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from keras-cv) (2022.10.31)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras-cv) (23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from keras-cv) (1.4.0)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (1.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (8.1.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (4.65.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (1.13.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (2.2.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (3.20.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (1.14.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras-cv) (5.9.4)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras-cv) (4.5.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras-cv) (5.12.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras-cv) (3.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (1.26.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.59.0)\n",
            "Installing collected packages: keras-cv\n",
            "Successfully installed keras-cv-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/gdrive/MyDrive/sd-playground/\n",
        "\n",
        "savedir = \"/content/gdrive/MyDrive/sd-playground/\"\n",
        "\n",
        "#!git clone https://github.com/keras-team/keras-cv.git\n",
        "!pip install --upgrade keras-cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJNbZKsAr2qr",
        "outputId": "1d9df09b-ed84-4911-c65f-0165ae7d5c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n",
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "\n",
        "from datetime import datetime \n",
        "\n",
        "model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)\n",
        "MAX_PROMPT_LENGTH = 77\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tp-mA15QoSt",
        "outputId": "3e31193a-6b06-40d4-d58d-6338a7a37064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 6s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 41s 0us/step\n",
            "25/25 [==============================] - 168s 3s/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\n",
            "198180272/198180272 [==============================] - 1s 0us/step\n",
            "0 before -0.38837656\n",
            "0 after -0.662327\n",
            "25/25 [==============================] - 85s 3s/step\n",
            "1 before -0.38837656\n",
            "1 after -0.33636737\n",
            "25/25 [==============================] - 88s 4s/step\n",
            "2 before -0.38837656\n",
            "2 after -0.29784065\n",
            " 4/25 [===>..........................] - ETA: 1:28"
          ]
        }
      ],
      "source": [
        "\n",
        "rng = default_rng()\n",
        "\n",
        "def plot_images(images):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "def plot_images_2d(images, inverted, zoom, savefile):\n",
        "    if inverted:\n",
        "      plt.figure(figsize=(zoom*len(images), zoom*len(images[0])))\n",
        "      for i in range(len(images)):\n",
        "        for j in range(len(images[i])):\n",
        "          ax = plt.subplot(len(images[0]), len(images), (j * len(images)) + i +1)\n",
        "          plt.imshow(images[i][j])\n",
        "          plt.axis(\"off\")\n",
        "    else:\n",
        "      plt.figure(figsize=(zoom*len(image[0]), zoom*len(images)))\n",
        "      for i in range(len(images)):\n",
        "        for j in range(len(images[i])):\n",
        "          ax = plt.subplot(len(images), len(images[0]), (i * len(images)) + j +1)\n",
        "          plt.imshow(images[i][j])\n",
        "          plt.axis(\"off\")\n",
        "\n",
        "    if (savefile):\n",
        "\n",
        "        plt.savefig(savefile+\".jpg\")\n",
        "\n",
        "def randnsphere(n,radius):\n",
        "  v = [rng.standard_normal() for i in range(0, n)]\n",
        "  inv_len = radius / math.sqrt(sum(coord * coord for coord in v))\n",
        "  return [coord * inv_len for coord in v]\n",
        "\n",
        "num_points = 10\n",
        "seed = 10000002\n",
        "num_steps=25\n",
        "batch_size = 4\n",
        "sphere_radius = 5\n",
        "\n",
        "prompt = \"boxer\"\n",
        "\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "phrase = tokens + [49407] * (MAX_PROMPT_LENGTH - len(tokens))\n",
        "phrase = tf.convert_to_tensor([phrase], dtype=tf.int32)\n",
        "context_base = model.text_encoder.predict_on_batch(\n",
        "    [phrase, model._get_pos_ids()]\n",
        ")\n",
        "\n",
        "rand_array = [np.array(randnsphere (768, sphere_radius)) for z in range (10)] \n",
        "img_rows = []\n",
        "img_rows.append (model.generate_image(context_base,num_steps=num_steps,seed=seed, batch_size=batch_size))\n",
        "\n",
        "for i in range(num_points):\n",
        "  context=context_base.copy()\n",
        "  print (str(i)+\" before \"+ str(context[0][0][0]))\n",
        "  around = np.array(context[0][0])+rand_array[i]\n",
        "  context[0][0] = around\n",
        "  print (str(i)+\" after \"+ str(context[0][0][0]))\n",
        "  img = model.generate_image(context,num_steps=num_steps,seed=seed, batch_size=batch_size)\n",
        "  img_rows.append(img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "savename = savedir+datetime.now().strftime(\"%Y%m%d%H%M%S\")+\"_\"+prompt\n",
        "plot_images_2d(img_rows,True,3, savename)\n",
        "params_array = np.array ([np.array([num_points,seed,num_steps,batch_size,sphere_radius]), rand_array])\n",
        "np.save (savename+\".npy\", params_array)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkUluITzT2650IY2xT7+F0",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}